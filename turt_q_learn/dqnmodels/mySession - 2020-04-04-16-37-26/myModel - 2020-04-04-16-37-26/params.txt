Action Dim: 5
Action Rate: 1
Batch Size: 64
Crash Penalty: -50
Direction Scalar: 1
Double Q Network: True
Episode Length: 350
Episodes: 400
Epsilon Decay: 0.992
Epsilon Initial: 1
Epsilon Min: 0.05
First Activation: <function relu at 0x7f22f02a0c50>
Gamma: 0.99
Goal Reward: 50
Hidden Activations: <function relu at 0x7f22f02a0c50>
Initializer: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x7f22ec7cab10>
Last Activation: <function linear at 0x7f22f02a0ed0>
Learning Rate: 0.0002
Load Model: False
Loss: <tensorflow.python.keras.losses.Huber object at 0x7f22ec7cab50>
Max Scan Range: 1
Memory Length: 1000000
Model Type: 2
Optimizer: <class 'tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop'>
Pause: False
Reset Target: 500
Reward Direction: True
Scan Ratio: 18
Scan Reward Scalar: 1
State Dim: 23
